/**
 * Complete registry of all 25+ AI models with their configurations
 */

import { ModelConfig } from '../types';

export const MODEL_REGISTRY: Record<string, ModelConfig> = {
  // ANTHROPIC FAMILY (7 models)
  'claude-opus-4.1': {
    id: 'claude-opus-4.1',
    name: 'Claude Opus 4.1',
    provider: 'anthropic',
    type: 'text',
    version: '4.1',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 200000,
      maxOutputTokens: 4096,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 15.0,
      outputTokenCost: 75.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 200000,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 2000,
      tokensPerSecond: 50,
      qualityScore: 98,
      reliabilityScore: 99,
      costEfficiency: 85,
      userSatisfaction: 97,
      successRate: 99.5,
      lastUpdated: new Date(),
    },
    specializations: ['advanced reasoning', 'complex coding', 'research', 'analysis'],
    description: 'Most powerful Claude model with exceptional reasoning and coding abilities',
    isAvailable: true,
  },
  'claude-opus-4': {
    id: 'claude-opus-4',
    name: 'Claude Opus 4',
    provider: 'anthropic',
    type: 'text',
    version: '4.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 200000,
      maxOutputTokens: 4096,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 15.0,
      outputTokenCost: 75.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 200000,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 2100,
      tokensPerSecond: 48,
      qualityScore: 97,
      reliabilityScore: 99,
      costEfficiency: 84,
      userSatisfaction: 96,
      successRate: 99.3,
      lastUpdated: new Date(),
    },
    specializations: ['reasoning', 'coding', 'analysis'],
    description: 'Powerful Claude model for complex tasks',
    isAvailable: true,
  },
  'claude-sonnet-4.5': {
    id: 'claude-sonnet-4.5',
    name: 'Claude Sonnet 4.5',
    provider: 'anthropic',
    type: 'text',
    version: '4.5',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 200000,
      maxOutputTokens: 8192,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 3.0,
      outputTokenCost: 15.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 200000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1200,
      tokensPerSecond: 75,
      qualityScore: 95,
      reliabilityScore: 99,
      costEfficiency: 95,
      userSatisfaction: 96,
      successRate: 99.7,
      lastUpdated: new Date(),
    },
    specializations: ['balanced performance', 'coding', 'general tasks'],
    description: 'Best balance of intelligence, speed, and cost',
    isAvailable: true,
  },
  'claude-sonnet-4': {
    id: 'claude-sonnet-4',
    name: 'Claude Sonnet 4',
    provider: 'anthropic',
    type: 'text',
    version: '4.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 200000,
      maxOutputTokens: 4096,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 3.0,
      outputTokenCost: 15.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 200000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1300,
      tokensPerSecond: 70,
      qualityScore: 94,
      reliabilityScore: 99,
      costEfficiency: 94,
      userSatisfaction: 95,
      successRate: 99.5,
      lastUpdated: new Date(),
    },
    specializations: ['general purpose', 'coding', 'analysis'],
    description: 'Balanced Claude model for most use cases',
    isAvailable: true,
  },
  'claude-sonnet-3.5': {
    id: 'claude-sonnet-3.5',
    name: 'Claude Sonnet 3.5',
    provider: 'anthropic',
    type: 'text',
    version: '3.5',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 200000,
      maxOutputTokens: 4096,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 3.0,
      outputTokenCost: 15.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 200000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1400,
      tokensPerSecond: 68,
      qualityScore: 92,
      reliabilityScore: 99,
      costEfficiency: 92,
      userSatisfaction: 94,
      successRate: 99.4,
      lastUpdated: new Date(),
    },
    specializations: ['coding', 'writing', 'general tasks'],
    description: 'Previous generation balanced model',
    isAvailable: true,
  },
  'claude-haiku-3.5': {
    id: 'claude-haiku-3.5',
    name: 'Claude Haiku 3.5',
    provider: 'anthropic',
    type: 'text',
    version: '3.5',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 200000,
      maxOutputTokens: 4096,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 0.25,
      outputTokenCost: 1.25,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 200,
      maxTokensPerRequest: 200000,
      maxConcurrentRequests: 50,
    },
    performance: {
      averageLatency: 400,
      tokensPerSecond: 150,
      qualityScore: 88,
      reliabilityScore: 99,
      costEfficiency: 98,
      userSatisfaction: 92,
      successRate: 99.6,
      lastUpdated: new Date(),
    },
    specializations: ['speed', 'cost efficiency', 'simple tasks'],
    description: 'Fastest and most cost-effective Claude model',
    isAvailable: true,
  },
  'claude-haiku-3': {
    id: 'claude-haiku-3',
    name: 'Claude Haiku 3',
    provider: 'anthropic',
    type: 'text',
    version: '3.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: false,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 200000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 0.25,
      outputTokenCost: 1.25,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 200,
      maxTokensPerRequest: 200000,
      maxConcurrentRequests: 50,
    },
    performance: {
      averageLatency: 500,
      tokensPerSecond: 140,
      qualityScore: 85,
      reliabilityScore: 99,
      costEfficiency: 97,
      userSatisfaction: 90,
      successRate: 99.5,
      lastUpdated: new Date(),
    },
    specializations: ['speed', 'cost', 'simple coding'],
    description: 'Previous generation fast model',
    isAvailable: true,
  },

  // OPENAI FAMILY (9 models)
  'gpt-4o': {
    id: 'gpt-4o',
    name: 'GPT-4o',
    provider: 'openai',
    type: 'multimodal',
    version: '4.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 128000,
      maxOutputTokens: 4096,
      visionCapable: true,
      audioCapable: true,
    },
    pricing: {
      inputTokenCost: 2.5,
      outputTokenCost: 10.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 500,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 100,
    },
    performance: {
      averageLatency: 1500,
      tokensPerSecond: 80,
      qualityScore: 95,
      reliabilityScore: 98,
      costEfficiency: 92,
      userSatisfaction: 95,
      successRate: 99.2,
      lastUpdated: new Date(),
    },
    specializations: ['multimodal', 'reasoning', 'general purpose'],
    description: 'OpenAI flagship multimodal model',
    isAvailable: true,
  },
  'gpt-4o-mini': {
    id: 'gpt-4o-mini',
    name: 'GPT-4o Mini',
    provider: 'openai',
    type: 'multimodal',
    version: '4.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 128000,
      maxOutputTokens: 16384,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 0.15,
      outputTokenCost: 0.6,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 500,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 100,
    },
    performance: {
      averageLatency: 600,
      tokensPerSecond: 120,
      qualityScore: 88,
      reliabilityScore: 98,
      costEfficiency: 96,
      userSatisfaction: 92,
      successRate: 99.3,
      lastUpdated: new Date(),
    },
    specializations: ['cost efficiency', 'speed', 'general tasks'],
    description: 'Cost-effective multimodal model',
    isAvailable: true,
  },
  'gpt-4-turbo': {
    id: 'gpt-4-turbo',
    name: 'GPT-4 Turbo',
    provider: 'openai',
    type: 'text',
    version: '4.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 128000,
      maxOutputTokens: 4096,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 10.0,
      outputTokenCost: 30.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 500,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 100,
    },
    performance: {
      averageLatency: 1800,
      tokensPerSecond: 70,
      qualityScore: 94,
      reliabilityScore: 98,
      costEfficiency: 88,
      userSatisfaction: 94,
      successRate: 99.1,
      lastUpdated: new Date(),
    },
    specializations: ['coding', 'reasoning', 'vision'],
    description: 'High performance GPT-4 variant',
    isAvailable: true,
  },
  'o1': {
    id: 'o1',
    name: 'o1',
    provider: 'openai',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: false,
      multimodal: false,
      webSearch: false,
      functionCalling: false,
      streaming: false,
      contextWindow: 128000,
      maxOutputTokens: 32768,
    },
    pricing: {
      inputTokenCost: 15.0,
      outputTokenCost: 60.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 20,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 5,
    },
    performance: {
      averageLatency: 15000,
      tokensPerSecond: 10,
      qualityScore: 99,
      reliabilityScore: 97,
      costEfficiency: 75,
      userSatisfaction: 96,
      successRate: 98.5,
      lastUpdated: new Date(),
    },
    specializations: ['advanced reasoning', 'complex math', 'research'],
    description: 'Advanced reasoning model with extended thinking',
    isAvailable: true,
    requiresApproval: true,
  },
  'o1-mini': {
    id: 'o1-mini',
    name: 'o1 Mini',
    provider: 'openai',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: false,
      multimodal: false,
      webSearch: false,
      functionCalling: false,
      streaming: false,
      contextWindow: 128000,
      maxOutputTokens: 16384,
    },
    pricing: {
      inputTokenCost: 3.0,
      outputTokenCost: 12.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 8000,
      tokensPerSecond: 15,
      qualityScore: 93,
      reliabilityScore: 97,
      costEfficiency: 85,
      userSatisfaction: 92,
      successRate: 98.8,
      lastUpdated: new Date(),
    },
    specializations: ['reasoning', 'math', 'coding'],
    description: 'Faster reasoning model for STEM tasks',
    isAvailable: true,
  },
  'gpt-3.5-turbo': {
    id: 'gpt-3.5-turbo',
    name: 'GPT-3.5 Turbo',
    provider: 'openai',
    type: 'text',
    version: '3.5',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 16385,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 0.5,
      outputTokenCost: 1.5,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 3500,
      maxTokensPerRequest: 16385,
      maxConcurrentRequests: 500,
    },
    performance: {
      averageLatency: 500,
      tokensPerSecond: 130,
      qualityScore: 80,
      reliabilityScore: 99,
      costEfficiency: 95,
      userSatisfaction: 88,
      successRate: 99.5,
      lastUpdated: new Date(),
    },
    specializations: ['speed', 'cost', 'simple tasks'],
    description: 'Fast and cost-effective legacy model',
    isAvailable: true,
  },
  'dall-e-3': {
    id: 'dall-e-3',
    name: 'DALL-E 3',
    provider: 'openai',
    type: 'image',
    version: '3.0',
    capabilities: {
      textGeneration: false,
      codeGeneration: false,
      reasoning: false,
      math: false,
      analysis: false,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: false,
      streaming: false,
      contextWindow: 4000,
      maxOutputTokens: 0,
    },
    pricing: {
      inputTokenCost: 0,
      outputTokenCost: 40.0, // per image
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 4000,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 10000,
      tokensPerSecond: 0,
      qualityScore: 95,
      reliabilityScore: 97,
      costEfficiency: 80,
      userSatisfaction: 94,
      successRate: 98.0,
      lastUpdated: new Date(),
    },
    specializations: ['image generation', 'creative', 'art'],
    description: 'Advanced image generation model',
    isAvailable: true,
  },
  'whisper-1': {
    id: 'whisper-1',
    name: 'Whisper',
    provider: 'openai',
    type: 'audio',
    version: '1.0',
    capabilities: {
      textGeneration: false,
      codeGeneration: false,
      reasoning: false,
      math: false,
      analysis: false,
      creative: false,
      multimodal: true,
      webSearch: false,
      functionCalling: false,
      streaming: false,
      contextWindow: 0,
      maxOutputTokens: 0,
      audioCapable: true,
    },
    pricing: {
      inputTokenCost: 6.0, // per minute
      outputTokenCost: 0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 0,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 5000,
      tokensPerSecond: 0,
      qualityScore: 92,
      reliabilityScore: 98,
      costEfficiency: 88,
      userSatisfaction: 91,
      successRate: 99.0,
      lastUpdated: new Date(),
    },
    specializations: ['audio transcription', 'speech-to-text', 'multilingual'],
    description: 'Speech recognition and transcription',
    isAvailable: true,
  },
  'tts-1': {
    id: 'tts-1',
    name: 'TTS-1',
    provider: 'openai',
    type: 'audio',
    version: '1.0',
    capabilities: {
      textGeneration: false,
      codeGeneration: false,
      reasoning: false,
      math: false,
      analysis: false,
      creative: false,
      multimodal: true,
      webSearch: false,
      functionCalling: false,
      streaming: true,
      contextWindow: 4096,
      maxOutputTokens: 0,
      audioCapable: true,
    },
    pricing: {
      inputTokenCost: 15.0, // per 1M characters
      outputTokenCost: 0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 4096,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 3000,
      tokensPerSecond: 0,
      qualityScore: 90,
      reliabilityScore: 98,
      costEfficiency: 85,
      userSatisfaction: 90,
      successRate: 99.2,
      lastUpdated: new Date(),
    },
    specializations: ['text-to-speech', 'voice synthesis', 'audio generation'],
    description: 'Text-to-speech synthesis',
    isAvailable: true,
  },

  // GOOGLE FAMILY (5 models)
  'gemini-2.0-flash-exp': {
    id: 'gemini-2.0-flash-exp',
    name: 'Gemini 2.0 Flash (Experimental)',
    provider: 'google',
    type: 'multimodal',
    version: '2.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: true,
      functionCalling: true,
      streaming: true,
      contextWindow: 1000000,
      maxOutputTokens: 8192,
      visionCapable: true,
      audioCapable: true,
    },
    pricing: {
      inputTokenCost: 0,
      outputTokenCost: 0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 10,
      maxTokensPerRequest: 1000000,
      maxConcurrentRequests: 2,
    },
    performance: {
      averageLatency: 2500,
      tokensPerSecond: 60,
      qualityScore: 93,
      reliabilityScore: 92,
      costEfficiency: 100,
      userSatisfaction: 90,
      successRate: 96.0,
      lastUpdated: new Date(),
    },
    specializations: ['experimental', 'multimodal', 'long context'],
    description: 'Experimental next-gen Gemini with massive context',
    isAvailable: true,
    requiresApproval: true,
  },
  'gemini-1.5-pro': {
    id: 'gemini-1.5-pro',
    name: 'Gemini 1.5 Pro',
    provider: 'google',
    type: 'multimodal',
    version: '1.5',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 2000000,
      maxOutputTokens: 8192,
      visionCapable: true,
      audioCapable: true,
    },
    pricing: {
      inputTokenCost: 1.25,
      outputTokenCost: 5.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 360,
      maxTokensPerRequest: 2000000,
      maxConcurrentRequests: 60,
    },
    performance: {
      averageLatency: 2000,
      tokensPerSecond: 65,
      qualityScore: 94,
      reliabilityScore: 97,
      costEfficiency: 93,
      userSatisfaction: 93,
      successRate: 98.5,
      lastUpdated: new Date(),
    },
    specializations: ['long context', 'multimodal', 'reasoning'],
    description: 'Most capable Gemini with 2M token context',
    isAvailable: true,
  },
  'gemini-1.5-flash': {
    id: 'gemini-1.5-flash',
    name: 'Gemini 1.5 Flash',
    provider: 'google',
    type: 'multimodal',
    version: '1.5',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 1000000,
      maxOutputTokens: 8192,
      visionCapable: true,
      audioCapable: true,
    },
    pricing: {
      inputTokenCost: 0.075,
      outputTokenCost: 0.3,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 1000,
      maxTokensPerRequest: 1000000,
      maxConcurrentRequests: 200,
    },
    performance: {
      averageLatency: 800,
      tokensPerSecond: 100,
      qualityScore: 89,
      reliabilityScore: 98,
      costEfficiency: 97,
      userSatisfaction: 91,
      successRate: 99.0,
      lastUpdated: new Date(),
    },
    specializations: ['speed', 'cost efficiency', 'multimodal'],
    description: 'Fast and efficient multimodal model',
    isAvailable: true,
  },
  'gemini-1.0-pro': {
    id: 'gemini-1.0-pro',
    name: 'Gemini 1.0 Pro',
    provider: 'google',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 32760,
      maxOutputTokens: 2048,
    },
    pricing: {
      inputTokenCost: 0.5,
      outputTokenCost: 1.5,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 360,
      maxTokensPerRequest: 32760,
      maxConcurrentRequests: 60,
    },
    performance: {
      averageLatency: 1200,
      tokensPerSecond: 75,
      qualityScore: 85,
      reliabilityScore: 98,
      costEfficiency: 90,
      userSatisfaction: 87,
      successRate: 98.8,
      lastUpdated: new Date(),
    },
    specializations: ['general purpose', 'cost effective'],
    description: 'Previous generation Gemini model',
    isAvailable: true,
  },
  'imagen-3': {
    id: 'imagen-3',
    name: 'Imagen 3',
    provider: 'google',
    type: 'image',
    version: '3.0',
    capabilities: {
      textGeneration: false,
      codeGeneration: false,
      reasoning: false,
      math: false,
      analysis: false,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: false,
      streaming: false,
      contextWindow: 2048,
      maxOutputTokens: 0,
    },
    pricing: {
      inputTokenCost: 0,
      outputTokenCost: 40.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 2048,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 8000,
      tokensPerSecond: 0,
      qualityScore: 94,
      reliabilityScore: 96,
      costEfficiency: 82,
      userSatisfaction: 92,
      successRate: 97.5,
      lastUpdated: new Date(),
    },
    specializations: ['image generation', 'photorealistic', 'creative'],
    description: 'Advanced image generation by Google',
    isAvailable: true,
  },

  // DEEPSEEK FAMILY (4 models)
  'deepseek-v3': {
    id: 'deepseek-v3',
    name: 'DeepSeek V3',
    provider: 'deepseek',
    type: 'text',
    version: '3.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 64000,
      maxOutputTokens: 8192,
    },
    pricing: {
      inputTokenCost: 0.27,
      outputTokenCost: 1.1,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 64000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1100,
      tokensPerSecond: 85,
      qualityScore: 92,
      reliabilityScore: 96,
      costEfficiency: 96,
      userSatisfaction: 91,
      successRate: 98.2,
      lastUpdated: new Date(),
    },
    specializations: ['reasoning', 'coding', 'math'],
    description: 'Latest DeepSeek flagship model',
    isAvailable: true,
  },
  'deepseek-coder': {
    id: 'deepseek-coder',
    name: 'DeepSeek Coder',
    provider: 'deepseek',
    type: 'code',
    version: '2.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: false,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 64000,
      maxOutputTokens: 8192,
      supportedLanguages: ['all'],
    },
    pricing: {
      inputTokenCost: 0.14,
      outputTokenCost: 0.28,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 64000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 900,
      tokensPerSecond: 95,
      qualityScore: 95,
      reliabilityScore: 97,
      costEfficiency: 98,
      userSatisfaction: 94,
      successRate: 98.8,
      lastUpdated: new Date(),
    },
    specializations: ['code generation', 'code review', 'debugging'],
    description: 'Specialized coding model',
    isAvailable: true,
  },
  'deepseek-chat': {
    id: 'deepseek-chat',
    name: 'DeepSeek Chat',
    provider: 'deepseek',
    type: 'text',
    version: '2.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 64000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 0.14,
      outputTokenCost: 0.28,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 64000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 800,
      tokensPerSecond: 100,
      qualityScore: 88,
      reliabilityScore: 97,
      costEfficiency: 95,
      userSatisfaction: 89,
      successRate: 98.5,
      lastUpdated: new Date(),
    },
    specializations: ['conversation', 'general tasks', 'cost effective'],
    description: 'General purpose chat model',
    isAvailable: true,
  },
  'deepseek-math': {
    id: 'deepseek-math',
    name: 'DeepSeek Math',
    provider: 'deepseek',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: false,
      reasoning: true,
      math: true,
      analysis: true,
      creative: false,
      multimodal: false,
      webSearch: false,
      functionCalling: false,
      streaming: true,
      contextWindow: 32000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 0.14,
      outputTokenCost: 0.28,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 32000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1500,
      tokensPerSecond: 70,
      qualityScore: 96,
      reliabilityScore: 96,
      costEfficiency: 94,
      userSatisfaction: 93,
      successRate: 98.0,
      lastUpdated: new Date(),
    },
    specializations: ['mathematics', 'equations', 'problem solving'],
    description: 'Specialized mathematical reasoning model',
    isAvailable: true,
  },

  // MISTRAL FAMILY (5 models)
  'mistral-large-2': {
    id: 'mistral-large-2',
    name: 'Mistral Large 2',
    provider: 'mistral',
    type: 'text',
    version: '2.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 128000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 2.0,
      outputTokenCost: 6.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1400,
      tokensPerSecond: 75,
      qualityScore: 93,
      reliabilityScore: 97,
      costEfficiency: 91,
      userSatisfaction: 92,
      successRate: 98.5,
      lastUpdated: new Date(),
    },
    specializations: ['reasoning', 'coding', 'multilingual'],
    description: 'Flagship Mistral model',
    isAvailable: true,
  },
  'mistral-medium': {
    id: 'mistral-medium',
    name: 'Mistral Medium',
    provider: 'mistral',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 32000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 2.7,
      outputTokenCost: 8.1,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 32000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1200,
      tokensPerSecond: 80,
      qualityScore: 90,
      reliabilityScore: 97,
      costEfficiency: 88,
      userSatisfaction: 90,
      successRate: 98.3,
      lastUpdated: new Date(),
    },
    specializations: ['balanced', 'general purpose'],
    description: 'Balanced Mistral model',
    isAvailable: true,
  },
  'mistral-small': {
    id: 'mistral-small',
    name: 'Mistral Small',
    provider: 'mistral',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 32000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 0.2,
      outputTokenCost: 0.6,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 200,
      maxTokensPerRequest: 32000,
      maxConcurrentRequests: 40,
    },
    performance: {
      averageLatency: 700,
      tokensPerSecond: 110,
      qualityScore: 85,
      reliabilityScore: 98,
      costEfficiency: 95,
      userSatisfaction: 88,
      successRate: 98.8,
      lastUpdated: new Date(),
    },
    specializations: ['speed', 'cost', 'simple tasks'],
    description: 'Fast and cost-effective model',
    isAvailable: true,
  },
  'codestral': {
    id: 'codestral',
    name: 'Codestral',
    provider: 'mistral',
    type: 'code',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: false,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 32000,
      maxOutputTokens: 4096,
      supportedLanguages: ['all'],
    },
    pricing: {
      inputTokenCost: 0.2,
      outputTokenCost: 0.6,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 32000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 900,
      tokensPerSecond: 90,
      qualityScore: 92,
      reliabilityScore: 97,
      costEfficiency: 96,
      userSatisfaction: 92,
      successRate: 98.6,
      lastUpdated: new Date(),
    },
    specializations: ['code generation', 'fill-in-the-middle', 'completion'],
    description: 'Specialized code generation model',
    isAvailable: true,
  },
  'pixtral': {
    id: 'pixtral',
    name: 'Pixtral',
    provider: 'mistral',
    type: 'multimodal',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: false,
      reasoning: true,
      math: false,
      analysis: true,
      creative: true,
      multimodal: true,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 128000,
      maxOutputTokens: 4096,
      visionCapable: true,
    },
    pricing: {
      inputTokenCost: 0.2,
      outputTokenCost: 0.6,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1600,
      tokensPerSecond: 70,
      qualityScore: 89,
      reliabilityScore: 96,
      costEfficiency: 92,
      userSatisfaction: 90,
      successRate: 97.8,
      lastUpdated: new Date(),
    },
    specializations: ['vision', 'multimodal', 'image understanding'],
    description: 'Vision-capable multimodal model',
    isAvailable: true,
  },

  // OTHER MODELS
  'perplexity-sonar-pro': {
    id: 'perplexity-sonar-pro',
    name: 'Perplexity Sonar Pro',
    provider: 'perplexity',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: true,
      functionCalling: true,
      streaming: true,
      contextWindow: 127072,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 3.0,
      outputTokenCost: 15.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 127072,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 3000,
      tokensPerSecond: 60,
      qualityScore: 91,
      reliabilityScore: 95,
      costEfficiency: 86,
      userSatisfaction: 92,
      successRate: 97.5,
      lastUpdated: new Date(),
    },
    specializations: ['web search', 'research', 'real-time information'],
    description: 'Advanced model with real-time web search',
    isAvailable: true,
  },
  'perplexity-sonar': {
    id: 'perplexity-sonar',
    name: 'Perplexity Sonar',
    provider: 'perplexity',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: true,
      functionCalling: true,
      streaming: true,
      contextWindow: 127072,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 1.0,
      outputTokenCost: 1.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 127072,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 2500,
      tokensPerSecond: 65,
      qualityScore: 88,
      reliabilityScore: 95,
      costEfficiency: 90,
      userSatisfaction: 90,
      successRate: 97.8,
      lastUpdated: new Date(),
    },
    specializations: ['web search', 'research', 'current events'],
    description: 'Model with integrated web search',
    isAvailable: true,
  },
  'llama-3.3-70b': {
    id: 'llama-3.3-70b',
    name: 'Llama 3.3 70B',
    provider: 'meta',
    type: 'text',
    version: '3.3',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 128000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 0.6,
      outputTokenCost: 0.6,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1300,
      tokensPerSecond: 80,
      qualityScore: 90,
      reliabilityScore: 96,
      costEfficiency: 94,
      userSatisfaction: 90,
      successRate: 98.0,
      lastUpdated: new Date(),
    },
    specializations: ['open source', 'general purpose', 'multilingual'],
    description: 'Latest Llama model from Meta',
    isAvailable: true,
  },
  'llama-3.1-405b': {
    id: 'llama-3.1-405b',
    name: 'Llama 3.1 405B',
    provider: 'meta',
    type: 'text',
    version: '3.1',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 128000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 3.0,
      outputTokenCost: 3.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 50,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 2500,
      tokensPerSecond: 50,
      qualityScore: 94,
      reliabilityScore: 95,
      costEfficiency: 88,
      userSatisfaction: 92,
      successRate: 97.5,
      lastUpdated: new Date(),
    },
    specializations: ['large scale', 'reasoning', 'coding'],
    description: 'Largest open source Llama model',
    isAvailable: true,
  },
  'qwen-2.5': {
    id: 'qwen-2.5',
    name: 'Qwen 2.5',
    provider: 'meta',
    type: 'text',
    version: '2.5',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: false,
      functionCalling: true,
      streaming: true,
      contextWindow: 32768,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 0.3,
      outputTokenCost: 0.3,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 32768,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1000,
      tokensPerSecond: 85,
      qualityScore: 87,
      reliabilityScore: 96,
      costEfficiency: 93,
      userSatisfaction: 88,
      successRate: 98.2,
      lastUpdated: new Date(),
    },
    specializations: ['multilingual', 'Chinese', 'coding'],
    description: 'Advanced multilingual model from Alibaba',
    isAvailable: true,
  },
  'command-r-plus': {
    id: 'command-r-plus',
    name: 'Command R+',
    provider: 'cohere',
    type: 'text',
    version: '1.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: true,
      functionCalling: true,
      streaming: true,
      contextWindow: 128000,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 2.5,
      outputTokenCost: 10.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 100,
      maxTokensPerRequest: 128000,
      maxConcurrentRequests: 20,
    },
    performance: {
      averageLatency: 1500,
      tokensPerSecond: 70,
      qualityScore: 91,
      reliabilityScore: 96,
      costEfficiency: 89,
      userSatisfaction: 90,
      successRate: 98.0,
      lastUpdated: new Date(),
    },
    specializations: ['RAG', 'enterprise', 'multilingual'],
    description: 'Enterprise-focused model from Cohere',
    isAvailable: true,
  },
  'grok-2': {
    id: 'grok-2',
    name: 'Grok 2',
    provider: 'xai',
    type: 'text',
    version: '2.0',
    capabilities: {
      textGeneration: true,
      codeGeneration: true,
      reasoning: true,
      math: true,
      analysis: true,
      creative: true,
      multimodal: false,
      webSearch: true,
      functionCalling: true,
      streaming: true,
      contextWindow: 131072,
      maxOutputTokens: 4096,
    },
    pricing: {
      inputTokenCost: 2.0,
      outputTokenCost: 10.0,
      currency: 'USD',
    },
    limits: {
      maxRequestsPerMinute: 60,
      maxTokensPerRequest: 131072,
      maxConcurrentRequests: 10,
    },
    performance: {
      averageLatency: 1800,
      tokensPerSecond: 65,
      qualityScore: 90,
      reliabilityScore: 94,
      costEfficiency: 87,
      userSatisfaction: 89,
      successRate: 96.5,
      lastUpdated: new Date(),
    },
    specializations: ['real-time data', 'web search', 'humor'],
    description: 'X.AI model with real-time information',
    isAvailable: false,
    requiresApproval: true,
  },
};

export function getModelById(modelId: string): ModelConfig | undefined {
  return MODEL_REGISTRY[modelId];
}

export function getModelsByProvider(provider: string): ModelConfig[] {
  return Object.values(MODEL_REGISTRY).filter(
    (model) => model.provider === provider
  );
}

export function getAvailableModels(): ModelConfig[] {
  return Object.values(MODEL_REGISTRY).filter((model) => model.isAvailable);
}

export function getModelsByCapability(capability: keyof ModelCapabilities): ModelConfig[] {
  return Object.values(MODEL_REGISTRY).filter(
    (model) => model.capabilities[capability] === true
  );
}

export function getModelsByType(type: string): ModelConfig[] {
  return Object.values(MODEL_REGISTRY).filter((model) => model.type === type);
}
